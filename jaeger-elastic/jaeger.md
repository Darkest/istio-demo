# Jaeger и распределенная трассировка

## Для чего нужен и из чего состоит

Jaeger это система распределенного трейсинга, основной задачей которой
является мониторинг и устранение неполадок в системах основанных на
микросервисах

### Термины

Кратко об основных териманах распределенного трейсинга

#### Спан(span)

Спан представляет собой логическое действие у которого есть имя
операции, время начала и продолжительность. Сп аны могут быть
многоуровневыми и упорядоченными для отображения цепочек вызовов
![Spans visualization](https://www.jaegertracing.io/img/spans-traces.png)


#### Трейс(trace)

Трейс - это путь исполнения\данных через систему(микросервисов), его
можно представить как напрвленый ацикличный граф

### Компоненты

Jaeger может быть развернут как все-в-одном исполняемый файл(образ), где
все компоненты запущены в рамках одного процесса, или как масштабируемая
распределнная система. Существует две основыне схемы развертывания:

- Коллектор записывает данные напрямую в хранилище
  ![Jaeger with direct storage](https://www.jaegertracing.io/img/architecture-v1.png)
- Коллектор записывает данные в кафку как в промежуточный буфер
  ![Jaeger with kafka](https://www.jaegertracing.io/img/architecture-v2.png)

>Коллектор - это составня часть Jaeger, которая принимает спаны от
>агентов и записывает их в хранилище

#### Клиентские библотеки Jaeger (Jaeger client libraries)

Клиентские библиотеки - это реализации
[OpenTracing API](https://opentracing.io/) на различных ЯП. Они
используются, чтобы оснастить приложения для распределенного трейсинга
вручную, либо с использованием ряда существующих открытых бибилиотек,
таких как Flask, DropWizard, gRPC и многих других, которые уже
поддерживают OpenTracing API

Оснащенный сервис создает спаны при получении новых запросов и добавляет
контекстную информацию(trace id, span id, и baggage(пользовательские
мета-данные)) в исходящие запросы. Вместе с запросами далее передаются
только идентификаторы и baggage, все остальные данные (имя операции,
тайминги выполнения, тэги и логи) не передаются далее по цепочке
вызовов. Вместо этого они асинхронно в фоновом режиме пересылаются в
jaeger-agent.
![Illustration of context propagation](https://www.jaegertracing.io/img/context-prop.png)

#### Агент (Agent)

Агент представялет собой сетевой демон-процесс, который получает спаны
посылаеммые по протоколу UDP. Далее он их объединяет их в пачки и
отправляет их дальше в коллектор. Агент расчитан на развертывание на
каждом хосте(поде) как инфраструктурный компонент(сайдкар). Агент
забирает на себя функции маршрутизации и поиска коллекторов.  
В случае развертывания приложений внутри сервис мэша, функции клиентской
библиотеки и агента берет на себя Envoy сайдкар, который самостоятельно
создает контекст и отправляет спаны коллектору.

#### Коллектор (Collector)

Коллектор получает трейсы от агентов и обрабатывает их. На текущий
момент обработка включает в себя валидацию, индексацию, трансформацию и
в конечном итоге запись в хранилище.

Хранилище является подключаемым компонентом, на текущий момент
поддерживаются Cassandra, Elasticsearch и Kafka.

#### Query

Query это сервис, который получает трейсы из хранилища и предоставляет
интерфейс для их просмотра

#### Ingester

Ingester это сервис для переноса трейсов из кафки в другое хранилище
(Cassandra, Elasticsearch)

## Подход к трейсингу в istio

Задачу по формированию спанов и отправки их на коллектор в сервис меше
решает Envoy, установленный в качестве сайдкара на подах и используемый
в качестве ингресс и егресс гейтвеев.

Envoy:
- генерирует id запроса и заголовки для трассировки(например,
  X-B3-TraceId) для всех запросов (в случае, если они отсутствуют в
  запросе) при их прохождении через сайдкар
- генерирует спаны для кажого запроса, основываясь на метаданных запроса
  и ответа(например, время ответа)
- отправляет сгенерированные спаны в коллектор
- пробрасывает заголовки запроса(вместе с самим запросом) в сервис

В отличие от многих других функций istio, для полноценной работы
трейсинга необходима частичная доработка пользовательских сервисов. Для
того, чтобы Jaeger мог связать множественные спаны в один трейс, сервисы
при вызове других сервисов должны пробрасывать следующие заголовки из
пришедших запросов в исходящие:
- x-request-id
- x-b3-traceid
- x-b3-spanid
- x-b3-parentspanid
- x-b3-sampled
- x-b3-flags
- b3

## Настройка трейсинга в OpenShift Jaeger Operator

OpenShift Jaeger Operator позволяет развернуть поды Jaeger в указанном
неймспейсе. При этом существует 3 варианта развертывания Jaeger с
использованием Jaeger Operator в OpenShift для этих целей:
- allInOne(задается по-умолчанию) подходит ТОЛЬКО для тестовых сред,
  внутри одного пода разворачивается один контейнер со всеми
  компонентами Jaeger(в качестве хранилища используется оперативная
  память).
- production используется для сред, где необходимо обеспечить длительное
  хранение трассировочных данных, отказоустойчивость и мастабируемость
  системы трассировки. Соответственно, все компоненты Jaeger и
  компоненты хранилища(Elasticsearch) разворачиваются отдельно друг от
  друга. Для обеспечения отказоустойчивости и мастабируемости все
  компоненты могут иметь множественно реплик
- streaming является более продвинутой стратегией развертывания,
  базирующейся на production стратегии. При ее использовании между
  коллектором и хранилищем добавляется потоковый сервис(kafka). Это
  позволяет снизать нагрузку на хранилище и добавить возможности
  дополнительного потокового анализа трассировок напрямую из потокового
  сервиса.

Данный подход на данный момент не является целевым и соответственно не
рассматривается подробно в рамках данного руководства

## Настройка трейсинга в OpenShift Service Mesh

### Внутри кластера

OpenShift Service Mesh поддерживает распределенную трасировку "из
коробки". При этом существует 3 варианта развертывания Jaeger с
использованием Jaeger Operator в OpenShift для этих целей:
- all-in-one(задается по-умолчанию) подходит ТОЛЬКО для тестовых сред,
  внутри одного пода разворачивается один контейнер со всеми
  компонентами Jaeger(в качестве хранилища используется оперативная
  память).
- production-elasticsearch используется для сред, где необходимо
  обеспечить длительное хранение трассировочных данных,
  отказоустойчивость и мастабируемость системы трассировки.
  Соответственно, все компоненты Jaeger и компоненты
  хранилища(Elasticsearch) разворачиваются отдельно друг от друга. Для
  обеспечения отказоустойчивости и мастабируемости все компоненты могут
  иметь множественно реплик

Для включения функции трейсинга в OpenShift Istio необходимо настроить
Control plane istio service mesh

```yaml
spec:
  istio:
    tracing:
      enabled: true
      jaeger:
        template: all-in-one # тип развертывания jaeger
```

или

```yaml
spec:
  istio:
    tracing:
      enabled: false
      ingress:
        enabled: true
      jaeger:
        elasticsearch:
          nodeCount: 1
          redundancyPolicy: null
          resources:
            limits:
              cpu: 500m
              memory: 1Gi
            requests:
              cpu: 500m
              memory: 1Gi
        template: production-elasticsearch
```

Настройки выше позволяет автоматизированно развернуть в Control Plane
istio все компоненты необходимые для трассировки нагрузки в кластере.  
Все компоненты при этом будут развернуты внутри неймспейса в котором
находится Control Plane istio

Но данный подход не всегда подходит для продакшн сред. Часто бывает так,
что компоненты системы трейсинга нуно разместить за пределами кластера,
например, в случае недоступности в кластере персистентного
хранилища(Persistent volumes)

Необходимо отдельно отметить что при автоматизированном развертывании
(spec.istio.tracing.enabled: true) компонентов внутри кластера выбор
хранилища трейсов и потокового сервиса ограничен Elasticserch.

### Снаружи кластера

Какие из компонентов можно вынести за пределы кластера:
- Коллектор
- Ingester
- Query
- Хранилище(elasticsearch)
- Потоковый сервис(kafka)


\- то есть, все компоненты кроме Агента, который по своей функции должен
находится рядом с приложениями в меше

Несмотря на то что каждый из компонентов можно вынести за пределы
кластера независимо от других, наиболее подходящими видятся следующие
варианты размещения:
- Все компоненты внутри кластера
- Все компоненты, кроме Агентов, внаружи кластера
- Все компоненты, кроме Агентов и Коллекторов, снаружи кластера

#### Все компоненты, кроме Агентов, cнаружи кластера

Для нас Для настройки такого варианта развертывания наобходимо выпонить
следующие шаги.тройки такого варианта развертывания наобходимо выпонить
следующие шаги.

Необходимо в настройках истио(доступны в виде ConfigMap 'istio' в
неймспейсе Control Plane) указать адрес коллектора трейсов. В случае
если в кластере запрещен исходящий трафик, необходимо дополнительно
создать ServiceEntry для доступа к внешнему коллектору.

```yaml
tracing:
    zipkin:
      # Address of the Zipkin collector
      address: <адрес>:<порт>
```

Если вы хотите также видеть в трейсах поды ингресса и егресса(и,
возможно, всех других компонентов istio), то необходимо поменять адрес в
Deployment(настройка --zipkinAddress)

```yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: istio-ingressgateway
  namespace: istio-system
          image: >-
            registry.redhat.io/openshift-service-mesh/proxyv2-rhel8@sha256:96d9f45b773c9367880a6bfea263d99a691006514732ef8f8e40f79c98603c1a
          args:
            - proxy
            - router
            - '--domain'
            - $(POD_NAMESPACE).svc.cluster.local
            - '--log_output_level=default:info'
            - '--drainDuration'
            - 45s
            - '--parentShutdownDuration'
            - 1m0s
            - '--connectTimeout'
            - 10s
            - '--serviceCluster'
            - istio-ingressgateway
            - '--zipkinAddress' 
            - 'zipkin:9411'
            - '--proxyAdminPort'
            - '15000'
            - '--statusPort'
            - '15020'
            - '--controlPlaneAuthPolicy'
            - NONE
            - '--discoveryAddress'
            - 'istio-pilot:15010'
```

Для применения изменений может потребоваться рестарт всех подов с
приложениями и подов с ингресс/егресс гейтвеями

Но более простым вариантом настройки точки сбора трейсов является
настройка Service `zipkin` Изменение адреса в сервисе влияет как на
трассировку от приложений так и от ингресс\егресс

```yaml
kind: Service
apiVersion: v1
metadata:
  name: zipkin
  namespace: istio-system
spec:
  ports:
    - name: zipkin
      protocol: TCP
      port: 9411
      targetPort: 9411
  selector:
    app: jaeger-collector
    version: 1.18.1
```

Для применения изменений не нужно производить перезауск подов.

#### Все компоненты, кроме Агентов и Коллекторов, cнаружи кластера

Для развертывания такой схемы необходимо дополнительно к шагам выше
создать Deployment для создание подов c коллекторами.

```yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: jaeger-collector
  namespace: istio-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: jaeger-collector
      version: 1.18.1
  template:
    metadata:
      labels:
        app: jaeger-collector
        version: 1.18.1
      annotations:
        sidecar.istio.io/inject: 'false'
    spec:
      containers:
        - name: jaeger-collector
          image: 'jaegertracing/jaeger-collector'
          env:
            - name: SPAN_STORAGE_TYPE
              value: 'elasticsearch'
          args:
            - --es.server-urls=http://192.168.1.13:9200
            - --collector.zipkin.host-port=9411
            - --es.num-shards=1
            - --es.num-replicas=0
            - --log-level=debug
          imagePullPolicy: Always
          ports:
            - containerPort: 14269
              protocol: TCP
            - containerPort: 14268
              protocol: TCP
            - containerPort: 14267
              protocol: TCP
            - containerPort: 9411
              protocol: TCP
```

Необходимо указать адрес существующего кластера elasticsearch, без него
коллектор не стартует. `--es.server-urls=http://192.168.1.13:9200`

Неоходимо обязательно указывать параметр
`--collector.zipkin.host-port=9411` для запуска ендпоинта для принятия
спанов в формате zipkin (по-умлочанию ендпоинт не доступен)
